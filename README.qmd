---
title: "Progress Report" 
author: "William Amorosi & Sebastian Remond" 
format: gfm 
editor: visual
---

## Research Question

-   What is the impact of light rail openings on air pollution near its stations?

## Hypothesis

-   The introduction of the Valley Metro Light Rail in Phoenix-Mesa is expected to help alleviate the amount of PM2.5 released into the air, which would help decrease air quality diseases in the area. Phoenix_Mesa has experienced a significant increase in population, with a 16.31% rise from 2004 to 2012 (U.S Census Bureau, 2024), and the population keeps on rising. This population growth has led to congested roads and an increased demand for power. Both of these factors can contribute to higher levels of PM2.5 in the air. The Valley Metro Light Rail can help mitigate this by providing faster public transportation and helping reduce the number of cars on roads. With fewer cars in the streets, roads can help decongest faster. Overall, the impact of the light rail on air pollution in the Phoenix-Mesa region (Maricopa County) will increase as more people use the light rail, further reducing one of their biggest contributors to PM2.5 pollution.

## Data

```{r}
#| echo: false
#| warning: false
library("tidyverse") 
library("knitr") 
library("terra") 
library("maptiles")
library("RColorBrewer")
```

-   Timeline of interest

    -   Given the time frame of the data we have access to from NASA, the only stations that existed then all opened on December 27th, 2008. We want to track the pollution in an equal time frame before and after the opening, so we chose the time frame of January 1st, 2004 to January 1st, 2012

-   Station locations

    -   We used a Google API key to collect the coordinates of each of these stations, manually collecting the few that Google didn't automatically find.

        ```{r}
        c<-read.csv("Coordinates.csv") %>%   
          select(Station, lat2, lon2) 
        kable(c)
        ```

-   Factors that impact PM2.5 in the city

    Many factors contribute to the PM2.5 level in the air in Maricopa County, this is the Phoenix-Mesa area we are focusing on. According to Maricopa's official website, some of the biggest contributors to PM2.5 pollution include wood burning, power plants, congested highways, construction sites, and unpaved roads (Maricopa County, n.d). Using the same technique of acquiring their coordinates from Google API, we can make a table that contains some of the biggest contributors around this county, some more centralized in the city than others.

```{r}
sources <- read.csv("Poll_Coordinates.csv") %>%     
  filter(Source != "SOURCE Arizona") %>%     
  select(Source,lat2,lon2) 
kable(sources) 
```

## Plotting Stations

Once we had the coordinates, we could plot them out and create a map displaying the stations and the line they all service, as well as a circular buffer representing the station's area of effect.

```{r}
stations <- read.csv("Coordinates.csv") 
sources <- read.csv("Poll_Coordinates.csv")  
df<-stations |>   select(lon2, lat2)  
df2<-sources |>   select(lon2, lat2)  
#converts df into a spatvector 
x <- vect(df, geom=c("lon2", "lat2"), crs="+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs ") 
y <- vect(df2, geom=c("lon2", "lat2"), crs="+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs ") 
```

This would then put buffers over our stations with a 1000m radius. We get a more complete map by combining a map background, our points, and their station buffers.

```{r}
#create a 1 km (1000 meter) buffer (radius)  
pts_buffer<-buffer(x, width = 400) 
#approximate size of the background 
extent<-buffer(x, width = 400)  
bg <- get_tiles(ext(extent))  
plot(bg)  
#plotting the Stations and their buffers,as well as sources of pollution 
lines(pts_buffer) 
points(x, col = "red") 
points(y, col = "blue") 
outfile <- "buffer.shp" 
writeVector(pts_buffer, outfile, overwrite=TRUE) 
```

## **Gathering Meteorology Data**

To check the effects of pollution from sources around the city, whether it comes from stations, power plants, and highways or the effects of policies that might affect these levels of pollution, we need meteorological data. we will be using data from NASA, through its Land Data Assimilation System (LDAS) and its global counterpart (GLDAS). These data can be gathered from NASA's website listed in the reference section. We downloaded all relevant data into a Google Drive folder, ranging from the dates of 01/01/2000 to 30/12/20214. This already covers our original date range of 01/01/2000 to 01/01/2012.

The code below opens this data and loops through its files to only get the relevant dates. Next, it uses the buffer zones around the train stations to only put the data from these areas. Lastly, it puts it all into a CSV file.

```{r}
#| eval: false
files<-dir("G:/Shared drives/2024 FIRE Light Rail/DATA/GLDAS/")

output<-c()

for(i in 1822:4384){
  r<-rast(paste0("G:/Shared drives/2024 FIRE Light Rail/DATA/GLDAS/", files[i]))
  
  sta<-vect("buffer.shp")
  
  #crops raster to contain only buffers around stations
  int<-crop(r, sta,
            snap="in",
            mask=TRUE)
  
  #convert cropped raster into dataframe and fine average value
  metdf<-terra::extract(int, sta, fun="mean", na.rm=TRUE)  %>%
    summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE))) %>%
    select(-ID)
  
  metdf$date<-files[i]
  output<-rbind(output, metdf)
  print(files[i])
}
 
write.csv(output, "met_data.csv", row.names=F)
```

## **Gathering PM2.5 Data**

Similarly to meteorology data, we need to also gather PM2.5 to see the changes these stations have on this type of pollution. we focus on the same time frame as meteorology data. Our data comes from NASA's Socioeconomic Data and Application Center (SEDAC). We downloaded the data into another Google Drive folder. we then use a nested for-loop to go through each folder (which are months), and go through each day (they are TIF files containing satellite images of the US). The buffers we used for the meteorology data are also used again to focus on those parts of the map. We put all these daily files into a folder that will be used later on.

```{r}
#| eval: false
pts_buffer <- vect("buffer.shp")

path<-"G:/Shared drives/2024 FIRE Light Rail/DATA/PM25/"
months<-dir(path)
# for each month
for (m in 1:length(months)) {
  print(months[m])
  days<-dir(paste0(path,months[m]))
  
  # for each day in this month
  days_output<-c()
  for (d in 1:length(days)) {
    print(days[d])
    
    #read tif file
    r<-rast(paste0(path, months[m], "/", days[d]))
    
    #changes the crs system
    buffer_project<-terra::project(pts_buffer,  crs(r))
    
    #pts_buffer is the buffer around stations
    #crops raster to contain only buffers around stations
    int<-crop(r, buffer_project,
              snap="in",
              mask=TRUE)
    
    #convert cropped raster into dataframe and fine average value
    cntrl_df<-terra::extract(int, buffer_project, fun="mean", na.rm=TRUE)
    
    #rename columns
    names(cntrl_df)<-c("city_num","pm25")
    
    #create a dataframe date, shape index, and pm25
    output <- as.data.frame(c("date"=days[d], cntrl_df))
    
    #combine output with previous looop
    days_output<-rbind(days_output, output)
   
    
  }
  write.csv(days_output, 
            paste0("PM25_daily/lr_centroid_",
                   months[m],
                   ".csv")
            , row.names = F)
  
}
```

## **Combining All Data Gathered**

Now that we have station locations, sources of pollution locations, meteorology data, and PM2.5 data, we combine all of these into one single data frame. Holiday dates were added and compared to dates on the time frame to verify if those dates were holidays. all of the data are then combined into a data frame using merge() and outputted into a CSV file.

```{r}
#| eval: false
setwd("PM25_daily")
file_list <- list.files()

dataset<-data.frame()

for (file in file_list){
    temp_dataset <-read.csv(file)
    dataset<-rbind(dataset, temp_dataset)
    rm(temp_dataset)
}
setwd("..")
stations<-read.csv("Coordinates.csv")
merge1<-merge(dataset,stations, by.x = "city_num", by.y = "X")
newdates <- gsub("(....)(..)(..)(\\.tif)", "\\1-\\2-\\3", merge1$date)
merge1$date <- as.Date(newdates)
holidays <- read.csv("major_holidays_2000_2025.csv")
is_holiday <- newdates %in% holidays$date
merge1$is_holiday <- is_holiday
merge1$dow <- weekdays(merge1$date)
merge1$month <- format(merge1$date, "%m")
dfm<-read.csv("met_data.csv")
newdates2 <- as.Date(gsub("(....)(..)(..)(\\.020\\.nc4)", "\\1-\\2-\\3", dfm$date))
dfm$date <- newdates2
merge2<-merge(merge1, dfm, by.x="date", by.y="date")

write.csv(merge2, "Big_Data.csv")

```

## Modeling and Using DB-OLS Regression

Our goal now is to create a Discontinuity Based- Ordinary Least Square (DB-OLS) model, which is discussed in ‘Green Infrastructure: The Effects of Urban Rail Transit on Air Quality’ by Chen and Walley (2012). This model assumes that without the metro opening, there wouldn’t have been a sudden change in air quality in Taipei, holding everything else constant. Similarly, we are making the same assumption with the Valley Metro to see if its opening does cause a drastic change in PM2.5 pollution. We will establish our dates for the start of the analysis to the end of it, the opening date of the stations, when construction began for the stations, and a policy that was enacted around that same time. df2 contains our initial comprehensive data that was combined earlier, but it has been streamlined by removing unnecessary columns that won’t be used in the regression

```{r}
df<-read.csv("Big_Data.csv")
df2<-df %>% mutate(date=as.Date(date, format='%Y-%m-%d'))
df2 <- subset(df2, select = -c(V1, V2, V3, lon, lat, address, X, lat2, lon2, Station))

#period of analysis

startdate<-as.Date("2004-12-01", format='%Y-%m-%d')
enddate<-as.Date("2012-12-01", format='%Y-%m-%d')
opendate<-as.Date("2008-12-27", format='%Y-%m-%d')
conststart<-as.Date("2005-03-01", format='%Y-%m-%d')
poldate<-as.Date("2004-01-21", format='%Y-%m-%d')
```

We now add variables that will be used for the regression. we have a policy variable that would be a 1 when it is active and 0 when it is not. Like with Metro open, it just states which dates the metro stations where open or not. other variables are temperature, wind, humidity and time variable.

```{r}
df3<-df2 %>%
  filter(date>=startdate & date<=enddate) %>%
  mutate(policy=ifelse(date>=poldate, 1, 0)) %>%
  mutate(MetroOpen=ifelse(date>=opendate, 1, 0)) %>%
  mutate(dow=wday(date)) %>%
  mutate(construction=ifelse(date>conststart & date<opendate, 
                             1, 0)) %>%
  #Create P(t) variables
  mutate(t=as.numeric(date-startdate)) %>%
  mutate(t2=t^2, t3=t^3, t4=t^4) %>%
  #Create lagged values (do this for temperature, humidity, and wind speed)
  arrange(city_num, date) %>%
  group_by(city_num) %>%
  mutate(lag_temp=lag(Tair_f_tavg)) %>%
  mutate(lag_temp2=lag_temp^2, lag_temp3=lag_temp^3, lag_temp4=lag_temp^4) %>%
  mutate(lag_wind=lag(Wind_f_tavg)) %>%
  mutate(lag_wind2=lag_wind^2, lag_wind3=lag_wind^3, lag_wind4=lag_wind^4) %>%
  mutate(lag_hum=lag(Qair_f_tavg)) %>%
  mutate(lag_hum2=lag_hum^2, lag_hum3=lag_hum^3, lag_hum4=lag_hum^4) %>%
  mutate(MetroTime=MetroOpen*t, MetroTime2=MetroOpen*t2, MetroTime3=MetroOpen*t3, MetroTime4=MetroOpen*t4)
```

Our first simple regression is just to see the effect on PM2.5 when the metro is open. this is not a good model as it only considers one variable. we would need to add more variables to see if any hidden variables might be affecting the levels of pollution in our areas. so we begin to add more to the regression to see how the variable "Metro Open" changes with each regression and added variable.

```{r}
#simple regression
summary(m1<-lm(log(pm25) ~ MetroOpen + as.factor(dow) + as.factor(month), data=df3))

summary(m1<-lm(log(pm25) ~ MetroOpen + as.factor(dow) + as.factor(month) +Tair_f_tavg+lag_temp+lag_temp2 + lag_temp3 + lag_temp4 +Wind_f_tavg+lag_wind+ lag_wind2 + lag_wind3 + lag_wind4+Qair_f_tavg+lag_hum+lag_hum2 + lag_hum3 + lag_hum4+construction, data=df3))

summary(m1<-lm(log(pm25) ~ MetroOpen +Tair_f_tavg+lag_temp+lag_temp2 + lag_temp3 + lag_temp4 +Wind_f_tavg+lag_wind+ lag_wind2 + lag_wind3 + lag_wind4+Qair_f_tavg+lag_hum+lag_hum2 + lag_hum3 + lag_hum4+construction+is_holiday+t+t2+t3+t4 , data=df3))

summary(m1<-lm(log(pm25) ~ MetroOpen:as.factor(city_num)+Tair_f_tavg+lag_temp+lag_temp2 + lag_temp3 + lag_temp4 +Wind_f_tavg+lag_wind+ lag_wind2 + lag_wind3 + lag_wind4+Qair_f_tavg+lag_hum+lag_hum2 + lag_hum3 + lag_hum4+construction+is_holiday+t+t2+t3+t4 , data=df3))
```

## Creating a Map and Drawing Conclusions

From the regression we thought was best, we turned the map of the stations into a representation of which locations saw the largest increases/decreases, as well as showing the other nearby pollution sources.

```{r}
summary(m1<-lm(log(pm25) ~ MetroOpen:as.factor(city_num)+Tair_f_tavg+lag_temp+lag_temp2 + lag_temp3 + lag_temp4 +Wind_f_tavg+lag_wind+ lag_wind2 + lag_wind3 + lag_wind4+Qair_f_tavg+lag_hum+lag_hum2 + lag_hum3 + lag_hum4+construction+is_holiday+t+t2+t3+t4 , data=df3))

len_coef<-length(coef(m1))

#get coefficients of the station-level effect
coef<-coef(m1)[(len_coef-26): len_coef]

#get p values of the station-level effect (p<0.05 is statistically significant)
pval<-summary(m1)$coefficients[,4][(len_coef-26): len_coef]

kable(cbind(coef, pval), digits=2)
c1<-vect("buffer.shp")

c2<-subset(c1, c1$FID>0 & c1$FID<28)
c1df<-as.data.frame(c1)

coef2<-c(coef)*100
coefdf<-as.data.frame(coef2)
cities_coef<-cbind(c2, coefdf)

sources <- read.csv("Poll_Coordinates.csv")
dfy<- sources %>%
  filter(Source != "SOURCE Arizona") %>%
  select(lon2,lat2)
y <- vect(dfy, geom=c("lon2", "lat2"), crs="+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs ")

bgext<-buffer(c2, width=9000)

#get background map
bg <- get_tiles(ext(bgext),provider = "Esri.WorldShadedRelief", crop = TRUE)

plot(bg)

plot(cities_coef,
     "coef2",
     type="interval",
     breaks=c(-10, -5, 0, 5, 10, 15, 20),
     col=map.pal("gyr"),add=TRUE, legend="topright", plg=list(cex=1))

points(y, col = "blue", cex=3)
```

## Comparing Stations via Line Graph

To show the difference in pollution levels between a station in central Phoenix (station 8 in the following plot) and a station in Mesa (station 27 in the plot), we made a line graph showing the levels in each station and added a line of best fit to show that the Phoenix station saw consistently more pollution. The vertical black line marks the opening date of the light rail stations.

```{r}
df2<-df %>% filter(city_num==8 | city_num==27) %>% mutate(date = as.Date(date)) %>% 
  mutate(city_num2 = as.character(paste0(city_num, " line")))

pal<-c("red","blue","lightblue","orange")

ggplot(df2, aes(x=date, y=pm25, group=city_num)) + 
  geom_line(aes(color=as.factor(city_num))) +
  geom_smooth(aes(color=as.factor(city_num2))) +
  geom_vline(xintercept=as.numeric(as.Date("2008-01-01"))) +
  scale_color_manual(values=pal) + theme_bw() + labs(color = "Station Number") +
  xlab("Date") + ylab("PM2.5 Level")

```

## Conclusion

As shown, the stations in the middle of the line near the center of Phoenix saw an increase in air pollution, while stations closer to the ends of the line saw decreases. After a little more research, we discovered that this was likely due to the surrounding geography. The mountains around Phoenix meant that air pollution in the area would get trapped in the "bowl" that the mountains created, making the air quality worse over time (ADEQ, n.d). The stations near the ends of the line are not as affected by this phenomenon, and we can see that the light rails did have an effect in decreasing the air pollution in those areas.

## References

1.  U.S. Census Bureau. (2024). Resident Population in Phoenix-Mesa-Scottsdale, AZ (MSA) \[Data set\]. Federal Reserve Bank of St. Louis. Retrieved June 27, 2024, from <https://fred.stlouisfed.org/series/PHXPOP.>

2.  Chen, Y., & Whalley, A. (2012). Green Infrastructure: The Effects of Urban Rail Transit on Air Quality. *American Economic Journal: Economic Policy*, *4*(1), 58–97. <http://www.jstor.org/stable/41330431>\

3.  ADEQ Arizona Department of Environmental Quality. (n.d.). What Is an Inversion and How Does It Affect Air Quality? \[Web page\]. Azdeq.gov. Retrieved from <https://azdeq.gov/what-inversion-and-how-does-it-affect-air-quality>

4.  NASA Global Land Data Assimilation System Version 2 (GLDAS-2). (n.d.). Meteorological Data. NASA Hydrology Data and Information Services Center (HDISC). Retrieved from <https://ldas.gsfc.nasa.gov/gldas>

5.  NASA Socioeconomic Data and Applications Center (SEDAC). (n.d.). Daily and Annual PM2.5 Concentrations for the Contiguous United States, 1-km Grids, v1 (2000 - 2016). NASA Hydrology Data and Information Services Center (HDISC). Retrieved from <https://sedac.ciesin.columbia.edu/data/set/aqdh-pm2-5-o3-no2-concentrations-zipcode-contiguous-us-2000-2016>

6.  Maricopa County. (n.d.). Outreach. Retrieved from <https://www.maricopa.gov/5914/Outreach>

    ‌
